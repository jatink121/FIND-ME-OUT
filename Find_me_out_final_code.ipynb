{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZQ7ZsdFnNNG6en4ljk5Eqla8zsvQD-Jh",
      "authorship_tag": "ABX9TyMfP99KaGtiYDrTWFjIACVy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jatink121/FIND-ME-OUT/blob/main/Find_me_out_final_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Necessary Libraries:"
      ],
      "metadata": {
        "id": "K17TfnWmhdvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "t3NXznkshPMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the paths of images from drive"
      ],
      "metadata": {
        "id": "xX8JKTHVhljD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_train_path = '/content/drive/MyDrive/FIND ME OUT SOC/Donald_train'                 #Here I define a variable store paths of different folders containing training_images of donald\n",
        "dt_test_path = '/content/drive/MyDrive/FIND ME OUT SOC/Donald_test'                 #Here I define var to tore paths of different folders containing testing_images of donald\n",
        "rd_train_path = '/content/drive/MyDrive/FIND ME OUT SOC/RDJ_TRAIN'                 #Here I define var to store paths of different folders containing training_images of robert\n",
        "rd_test_path = '/content/drive/MyDrive/FIND ME OUT SOC/RDJ_TEST'                 #Here I define store paths of different folders containing testing_images of robert\n",
        "ws_train_path = '/content/drive/MyDrive/FIND ME OUT SOC/Will_train'                #Here I define store paths of different folders containing training_images of will\n",
        "ws_test_path = '/content/drive/MyDrive/FIND ME OUT SOC/Will_test'                #Here I define store paths of different folders containing testing_images of will\n",
        "ab_train_path = '/content/drive/MyDrive/FIND ME OUT SOC/Alia_train'                #Here I define store paths of different folders containing training_images of alia\n",
        "ab_test_path = '/content/drive/MyDrive/FIND ME OUT SOC/Alia_test'                 #Here I define store paths of different folders containing testing_images of alia"
      ],
      "metadata": {
        "id": "DpJjs1onhkCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating labels"
      ],
      "metadata": {
        "id": "t8-harcDABL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we define training labels\n",
        "#now we define labels for each person 0,1,2,3\n",
        "zeroes = 75\n",
        "ones   = 75\n",
        "twos   = 75\n",
        "threes = 75\n",
        "i=0\n",
        "labels =[]                         #list to store the labels\n",
        "while i<300 :\n",
        "  if i<75 :\n",
        "    labels.append(0)\n",
        "  elif i<150 :\n",
        "    labels.append(1)\n",
        "  elif i<225 :\n",
        "    labels.append(2)\n",
        "  else :\n",
        "    labels.append(3)\n",
        "  i+=1\n",
        "train_labels = np.array(labels)           #converting the list into np-array\n",
        "np.random.shuffle(train_labels)           #distributing labels to random indices"
      ],
      "metadata": {
        "id": "nQIUlYUto22r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now we will make test labels\n",
        "zeroes = 25\n",
        "ones   = 25\n",
        "twos   = 25\n",
        "threes = 25\n",
        "i=0\n",
        "labels =[]                         #list to store the labels\n",
        "while i<100 :\n",
        "  if i<25 :\n",
        "    labels.append(0)\n",
        "  elif i<50 :\n",
        "    labels.append(1)\n",
        "  elif i<75 :\n",
        "    labels.append(2)\n",
        "  else :\n",
        "    labels.append(3)\n",
        "  i+=1\n",
        "test_labels = np.array(labels)           #converting the list into np-array\n",
        "np.random.shuffle(test_labels)           #distributing labels to random indices"
      ],
      "metadata": {
        "id": "SjmNpiXZmlec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing images into list using os"
      ],
      "metadata": {
        "id": "syRKEy0b_v6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lets create a list of images of each person\n",
        "dt_train_list = os.listdir(dt_train_path)\n",
        "rd_train_list = os.listdir(rd_train_path)\n",
        "dt_test_list = os.listdir(dt_test_path)\n",
        "rd_test_list = os.listdir(rd_test_path)\n",
        "ws_train_list = os.listdir(ws_train_path)\n",
        "ws_test_list = os.listdir(ws_test_path)\n",
        "ab_train_list = os.listdir(ab_train_path)\n",
        "ab_test_list = os.listdir(ab_test_path)"
      ],
      "metadata": {
        "id": "B1d5wAUXrgGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here we read the images from files to generate training data,test data and convert labels to one hot labels"
      ],
      "metadata": {
        "id": "jo0-Zr_TA6Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now lets generate training data\n",
        "x_train = []\n",
        "a=0\n",
        "b=0\n",
        "c=0\n",
        "d=0\n",
        "i=0\n",
        "width =128         #these are for resizing the image\n",
        "height =128\n",
        "while i<300 :\n",
        "  print(i)\n",
        "  if train_labels[i]==0 :\n",
        "    dt = dt_train_list[a]\n",
        "    a+=1\n",
        "    img_path = os.path.join(dt_train_path, dt)          #reading image file\n",
        "    img = cv2.imread(img_path)\n",
        "    resized_img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)    #resizing the image\n",
        "    x_train.append(resized_img)\n",
        "\n",
        "  elif train_labels[i]==1 :\n",
        "    rd = rd_train_list[b]\n",
        "    b+=1\n",
        "    img_path = os.path.join(rd_train_path, rd)          #reading image file\n",
        "    img = cv2.imread(img_path)\n",
        "    resized_img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)    #resizing the image\n",
        "    x_train.append(resized_img)\n",
        "  elif train_labels[i]==2 :\n",
        "    ws = ws_train_list[c]\n",
        "    c+=1\n",
        "    img_path = os.path.join(ws_train_path, ws)          #reading image file\n",
        "    img = cv2.imread(img_path)\n",
        "    resized_img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)    #resizing the image\n",
        "    x_train.append(resized_img)\n",
        "  elif train_labels[i]==3 :\n",
        "    ab = ab_train_list[d]\n",
        "    d+=1\n",
        "    img_path = os.path.join(ab_train_path, ab)          #reading image file\n",
        "    img = cv2.imread(img_path)\n",
        "    resized_img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)    #resizing the image\n",
        "    x_train.append(resized_img)\n",
        "  else :\n",
        "    print(\"labels are wrong\")\n",
        "  i+=1\n",
        "x_train = np.array(x_train)\n"
      ],
      "metadata": {
        "id": "3F7AhArasPui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we will generate testing data\n",
        "x_test = []\n",
        "a=0\n",
        "b=0\n",
        "c=0\n",
        "d=0\n",
        "i=0\n",
        "width =128         #these are for resizing the image\n",
        "height =128\n",
        "while i<100 :\n",
        "  if test_labels[i]==0 :\n",
        "    dt = dt_test_list[a]\n",
        "    a+=1\n",
        "    img_path = os.path.join(dt_test_path, dt)          #reading image file\n",
        "    img = cv2.imread(img_path)\n",
        "    resized_img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)    #resizing the image\n",
        "    x_test.append(resized_img)\n",
        "\n",
        "  elif test_labels[i]==1 :\n",
        "    rd = rd_test_list[b]\n",
        "    b+=1\n",
        "    img_path = os.path.join(rd_test_path, rd)          #reading image file\n",
        "    img = cv2.imread(img_path)\n",
        "    resized_img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)    #resizing the image\n",
        "    x_test.append(resized_img)\n",
        "  elif test_labels[i]==2 :\n",
        "    ws = ws_test_list[c]\n",
        "    c+=1\n",
        "    img_path = os.path.join(ws_test_path, ws)          #reading image file\n",
        "    img = cv2.imread(img_path)\n",
        "    resized_img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)    #resizing the image\n",
        "    x_test.append(resized_img)\n",
        "  else :\n",
        "    ab = ab_test_list[d]\n",
        "    d+=1\n",
        "    img_path = os.path.join(ab_test_path, ab)          #reading image file\n",
        "    img = cv2.imread(img_path)\n",
        "    resized_img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)    #resizing the image\n",
        "    x_test.append(resized_img)\n",
        "  i+=1\n",
        "x_test = np.array(x_test)"
      ],
      "metadata": {
        "id": "q3thsEqWwdf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=4)\n",
        "one_hot_test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=4)"
      ],
      "metadata": {
        "id": "sCUNOu9Kp0Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model for face recognition"
      ],
      "metadata": {
        "id": "tQh-0LyaAfuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_vals = tf.keras.Input(shape=(128, 128, 3))\n",
        "\n",
        "# Convolutional layers\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(input_vals)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(256, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Flatten the output and add Dense layers\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "# Output layer with 4 neurons for 4 classes and softmax activation for multi-class classification\n",
        "output_vals = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = models.Model(inputs=input_vals, outputs=output_vals)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',  # For multi-class classification\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OsXz6Y8D8LB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentaion"
      ],
      "metadata": {
        "id": "fhMgnm9sISC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#since data is limited lets use data augmentation to effectively increase the data_size, it will\n",
        "#help avoid overfitting#if data augmentaion is not done, model often memorizes the data easily and\n",
        "#does not perform as good on test data\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "data_augment = ImageDataGenerator(\n",
        "    rotation_range=20,       # Random rotation (degrees)\n",
        "    width_shift_range=0.1,   # Random horizontal shift\n",
        "    height_shift_range=0.1,  # Random vertical shift\n",
        "    shear_range=0.2,         # Shear transformations\n",
        "    zoom_range=0.2,          # Random zoom\n",
        "    horizontal_flip=True,    # Random horizontal flip\n",
        "    fill_mode='nearest'      # How to fill any newly created pixels\n",
        ")\n",
        "data_augment.fit(x_train)"
      ],
      "metadata": {
        "id": "LXP72Rj1IQNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the models with training data"
      ],
      "metadata": {
        "id": "2wAGhTn0A_8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 50\n",
        "#lets define early stopping , it really helps a lot\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "model.fit(data_augment.flow(x_train, one_hot_train_labels, batch_size=batch_size),\n",
        "          steps_per_epoch=len(x_train) // batch_size,\n",
        "          epochs=epochs, callbacks = [early_stopping])\n"
      ],
      "metadata": {
        "id": "tDVTF0e99HmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model with test data, model gives acuracy of over 95 %"
      ],
      "metadata": {
        "id": "MSPJ8dKsTAXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, one_hot_test_labels)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phECqWhF92bA",
        "outputId": "c4ba2429-7645-418b-ca2c-ed2ee89a9359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 233ms/step - loss: 0.1450 - accuracy: 0.9500\n",
            "Test Accuracy: 0.949999988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model"
      ],
      "metadata": {
        "id": "vbsB9K7UTL_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/FIND ME OUT SOC/SOC_2023_jatin_face_detection_model')"
      ],
      "metadata": {
        "id": "rPS659MpS-M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing on Single Images"
      ],
      "metadata": {
        "id": "tJnCOff4kuLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "single_image = cv2.imread('/content/drive/MyDrive/FIND ME OUT SOC/Alia_train/Screenshot 2023-07-31 124426.png')\n",
        "width = 128\n",
        "height = 128\n",
        "single_image = cv2.resize(single_image, (width, height), interpolation=cv2.INTER_AREA)\n",
        "single_image = np.array(single_image)\n",
        "print(\"Shape of single_image:\", single_image.shape)\n",
        "single_image = np.expand_dims(single_image, axis=0)  # Add a batch dimension to the single image\n",
        "predictions = model.predict(single_image)\n",
        "predicted_class_index = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Print the result\n",
        "print(\"Predicted Class Index:\", predicted_class_index)"
      ],
      "metadata": {
        "id": "6KETinx5_C_9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}